# Primer Ejercicio

## Estructura del proyecto.

` ejercicio_4      data_customer_classification 1.xlsx      feature_engeenier.py      image          readme              1710647532614.png      output          test_create_target.txt          test_dropdataset.txt          test_pretransform_peridoc.txt          test_q25.txt          test_q50.txt          test_q75.txt          test_transform_date.txt          test_transform_peridic.txt          test_transform_tran_amount.txt      output.txt      problema.txt      readme.md      test_feature_engeenier.py      train.py`

Nota: Las pruebas unitarias fueron creadas para correr con pytest. Hay varios m茅todos que tienen diferentes verificaciones, es por eso que se cre贸  la carpeta output, donde cada archivo .txt es el resultado de las pruebas unitarias.

## Feature engeenier

En la estructura de las carpetas hay un dataset donde sea crea un pipeline de la ingenier铆a de caracterisiticas. Las transformaciones que le vamos a hacer al dataset son las siguientes fuciones

funci贸n en el c贸digo:

#### Funciones de Cuantiles (`q25`, `q50`, `q75`)

Estas funciones calculan el percentil 25, 50 (mediana) y 75 de una serie de pandas respectivamente.

#### Funci贸n `read_df`

Lee un archivo Excel llamado "data_customer_classification 1.xlsx" que se encuentra en el mismo directorio que el script y devuelve el DataFrame correspondiente.

#### Funci贸n `pretransform_peridoc`

Transforma la columna "trans_date" del DataFrame en seno y coseno del d铆a de la semana, representados como "weekday_sin" y "weekday_cos" respectivamente.

#### Funci贸n `transform_peridic`

Agrupa el DataFrame por "customer_id" y calcula la media, desviaci贸n est谩ndar, cuantiles 25, 50 y 75 de las columnas "weekday_sin" y "weekday_cos" para cada cliente.

#### Funci贸n `transform_date`

Agrupa el DataFrame por "customer_id" y calcula la fecha m铆nima, desviaci贸n est谩ndar, fecha m谩xima y rango (diferencia entre la fecha m谩xima y m铆nima) de la columna "trans_date" para cada cliente.

#### Funci贸n `transform_tran_amount`

Agrupa el DataFrame por "customer_id" y calcula el m铆nimo, desviaci贸n est谩ndar, m谩ximo y media de la columna "tran_amount" para cada cliente.

#### Funci贸n `create_target`

Crea la variable objetivo "type_consumer" basada en los percentiles 25 y 75 del n煤mero de transacciones de cada cliente. Los clientes se clasifican como tipo 0 si est谩n por debajo del percentil 25, tipo 1 entre el percentil 25 y 75, y tipo 2 por encima del percentil 75.

#### Funci贸n `dropdataset`

Elimina la columna "customer_id" del DataFrame.

#### Funci贸n `extract_feature`

Es la funci贸n principal que ejecuta todas las transformaciones y operaciones anteriores en el DataFrame para extraer las caracter铆sticas deseadas.

En resumen, el c贸digo realiza una serie de operaciones de preprocesamiento y transformaci贸n en un conjunto de datos para obtener caracter铆sticas relevantes y crear una variable objetivo para el an谩lisis posterior.

## Entrenamiento del modelo

El c贸digo proporcionado se encarga de construir, entrenar y evaluar una red neuronal utilizando TensorFlow y Keras para un conjunto de datos previamente procesado. A continuaci贸n, se detalla qu茅 hace cada funci贸n en el c贸digo:

#### Funci贸n `create_train_test`

Esta funci贸n utiliza la funci贸n `extract_feature` del m贸dulo `feature_engineer` para obtener un DataFrame con caracter铆sticas preprocesadas. Luego, separa las caracter铆sticas (`X`) de la variable objetivo (`y`), estandariza las caracter铆sticas utilizando `StandardScaler`, y divide el conjunto de datos en conjuntos de entrenamiento y prueba utilizando `train_test_split`. Devuelve los conjuntos de datos de entrenamiento y prueba (`X_train`, `X_test`, `y_train`, `y_test`).

#### Funci贸n `create_nn`

Esta funci贸n crea una red neuronal secuencial utilizando Keras. La arquitectura de la red consta de una capa densa con 64 neuronas y activaci贸n ReLU, seguida de una capa densa con 32 neuronas y activaci贸n ReLU, y finalmente una capa densa con 3 neuronas de salida y activaci贸n softmax para clasificaci贸n en 3 categor铆as.

#### Funci贸n `train`

Esta funci贸n entrena el modelo de red neuronal utilizando el optimizador Adam y la p茅rdida `sparse_categorical_crossentropy`. Utiliza los conjuntos de datos de entrenamiento (`X_train`, `y_train`) durante un n煤mero especificado de 茅pocas y con un tama帽o de lote de 32.

#### Funci贸n `evaluate`

Esta funci贸n eval煤a el modelo entrenado utilizando los conjuntos de datos de prueba (`X_test`, `y_test`). Utiliza el modelo para predecir las etiquetas de las muestras de prueba y luego imprime un informe de clasificaci贸n que incluye m茅tricas como precisi贸n, recuperaci贸n y puntuaci贸n F1.

#### Funci贸n `main`

Esta es la funci贸n principal que coordina todas las operaciones. Llama a las funciones `create_train_test`, `create_nn`, `train` y `evaluate` en secuencia para crear, entrenar y evaluar la red neuronal.

En resumen, el c贸digo carga un conjunto de datos previamente procesado, construye una red neuronal, la entrena y luego eval煤a su rendimiento utilizando m茅tricas de clasificaci贸n.

## Correr el c贸digo online

[![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/Frorozcoloa/GBM)

## Correr en docker

1. Entramos a la carpeta `cd ejercio_4`
2. creamos la imagen `docker build -t train:_image .  `
3. Ejecutamos la imagen y abrimos la consola `docker run -it --name train_container train_image bash`

## Correr el c贸digo

1. Para correr el c贸digo necesita hacer lo siguiente.
2. Estar en la carpeta raiz.
3. crear un virtual env e instalar los requirements.txt `pip install ejercicio_4/`/requirements.txt`
4. Rectifica que el dataset se encuentre en ejercicio_4 y ejecutar `python ejercicio_4/train.py   `
5. Al final debe imprimirse las metricas de testeo, como en la siguiente imagen

   ![1710647532614](image/readme/1710647532614.png)
